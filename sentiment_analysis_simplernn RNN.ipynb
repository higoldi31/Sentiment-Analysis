{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "vR6C9i-fyLvG"
   },
   "outputs": [],
   "source": [
    "docs = ['go india',\n",
    "\t\t'india india',\n",
    "\t\t'hip hip hurray',\n",
    "\t\t'jeetega bhai jeetega india jeetega',\n",
    "\t\t'bharat mata ki jai',\n",
    "\t\t'kohli kohli',\n",
    "\t\t'sachin sachin',\n",
    "\t\t'dhoni dhoni',\n",
    "\t\t'modi ji ki jai',\n",
    "\t\t'inquilab zindabad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "xRzvJNh1mRQW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "2IhkPg6YmRYT"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dP5g_Tmin4AG",
    "outputId": "219ad8f6-9390-4da8-afcd-d51a13a5b1e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lOv8NrFFmRcE",
    "outputId": "eb3fbafe-991a-450a-e4f8-2988c5df6525"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 1],\n",
       " [1, 1],\n",
       " [3, 3, 10],\n",
       " [2, 11, 2, 1, 2],\n",
       " [12, 13, 4, 5],\n",
       " [6, 6],\n",
       " [7, 7],\n",
       " [8, 8],\n",
       " [14, 15, 4, 5],\n",
       " [16, 17]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KG1RqcLnmRkA",
    "outputId": "d497ded2-754f-457b-80f3-a4a69bbf1373"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  1,  0,  0,  0],\n",
       "       [ 1,  1,  0,  0,  0],\n",
       "       [ 3,  3, 10,  0,  0],\n",
       "       [ 2, 11,  2,  1,  2],\n",
       "       [12, 13,  4,  5,  0],\n",
       "       [ 6,  6,  0,  0,  0],\n",
       "       [ 7,  7,  0,  0,  0],\n",
       "       [ 8,  8,  0,  0,  0],\n",
       "       [14, 15,  4,  5,  0],\n",
       "       [16, 17,  0,  0,  0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import pad_sequences\n",
    "sequences = pad_sequences(sequences,padding='post')\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ETWEOn4wmRzd",
    "outputId": "b0ac8b69-117d-466c-ae34-422ffe7a90e1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(17,output_dim=2,input_length=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "R68ghDfNmSAC"
   },
   "outputs": [],
   "source": [
    "model.compile('adam','accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooYWO2NwoKoQ",
    "outputId": "62b763d3-07b0-49d5-a2ca-23fe55c4ee7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F20A291DA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
      "[[[-4.5054961e-02 -1.0500956e-02]\n",
      "  [ 2.0313989e-02  2.8030168e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]]\n",
      "\n",
      " [[ 2.0313989e-02  2.8030168e-02]\n",
      "  [ 2.0313989e-02  2.8030168e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]]\n",
      "\n",
      " [[-1.0020815e-02  4.9957875e-02]\n",
      "  [-1.0020815e-02  4.9957875e-02]\n",
      "  [ 2.0175967e-02  3.4731094e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]]\n",
      "\n",
      " [[-1.1364259e-02  3.7252579e-02]\n",
      "  [-2.0971075e-03 -3.4051098e-02]\n",
      "  [-1.1364259e-02  3.7252579e-02]\n",
      "  [ 2.0313989e-02  2.8030168e-02]\n",
      "  [-1.1364259e-02  3.7252579e-02]]\n",
      "\n",
      " [[ 4.2195503e-02  7.1514398e-05]\n",
      "  [ 4.9048316e-02 -4.9979210e-02]\n",
      "  [-2.4830092e-02  5.4940954e-03]\n",
      "  [ 1.6959395e-02  3.5484675e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]]\n",
      "\n",
      " [[ 1.3935234e-02 -3.3022001e-02]\n",
      "  [ 1.3935234e-02 -3.3022001e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]]\n",
      "\n",
      " [[-7.6991431e-03  1.7011788e-02]\n",
      "  [-7.6991431e-03  1.7011788e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]]\n",
      "\n",
      " [[ 2.2312228e-02  4.0005092e-02]\n",
      "  [ 2.2312228e-02  4.0005092e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]]\n",
      "\n",
      " [[-4.3475676e-02  3.1435166e-02]\n",
      "  [-2.6762212e-02 -2.6207197e-02]\n",
      "  [-2.4830092e-02  5.4940954e-03]\n",
      "  [ 1.6959395e-02  3.5484675e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]]\n",
      "\n",
      " [[ 7.7565312e-03 -3.2755993e-02]\n",
      "  [ 7.7565312e-03 -3.2755993e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]\n",
      "  [-4.7976412e-02  2.7024936e-02]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sequences = np.clip(sequences, 0, 16)\n",
    "\n",
    "pred = model.predict(sequences)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "yrM0IXVamPLn"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,SimpleRNN,Embedding,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "4aH4HVjcyq1f"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "cu2UOZGUzAEF"
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train,padding='post',maxlen=50)\n",
    "X_test = pad_sequences(X_test,padding='post',maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aO412Krkz7EO",
    "outputId": "b4f2de4f-c1ba-4d76-c8b9-cf7087850a3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 50)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWXhm8vP_DO-",
    "outputId": "c3eb5f20-a438-4439-b5fe-640f215fb61c"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=2, input_length=50))\n",
    "model.add(SimpleRNN(32,return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGCAZ7Rm_fqH",
    "outputId": "6f6a73ab-fbd4-4a23-ea56-46e3f9358c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - acc: 0.5228 - loss: 0.6916 - val_acc: 0.7168 - val_loss: 0.5660\n",
      "Epoch 2/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - acc: 0.7599 - loss: 0.4963 - val_acc: 0.8071 - val_loss: 0.4270\n",
      "Epoch 3/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - acc: 0.8570 - loss: 0.3398 - val_acc: 0.8075 - val_loss: 0.4306\n",
      "Epoch 4/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - acc: 0.8810 - loss: 0.2941 - val_acc: 0.8048 - val_loss: 0.4569\n",
      "Epoch 5/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - acc: 0.8994 - loss: 0.2577 - val_acc: 0.7878 - val_loss: 0.5703\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "jAQETwiZikEY"
   },
   "outputs": [],
   "source": [
    "# Get the word index used by the IMDB dataset\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# Adjust indices (Keras reserves 0-3)\n",
    "word_index = {k: (v + 3) for k, v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_encode(text): \n",
    "    words = text.lower().split()\n",
    "    encoded = [1]  # Start token\n",
    "    for word in words:\n",
    "        encoded.append(word_index.get(word, 2))  # Unknown if not found\n",
    "    return pad_sequences([encoded], maxlen=50, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Sentiment score: 0.29067\n",
      "Prediction: Negative üòû\n"
     ]
    }
   ],
   "source": [
    "# Your custom sentence\n",
    "text = \"the movie was  bad\"\n",
    "\n",
    "# Encode and predict\n",
    "encoded = simple_encode(text)\n",
    "pred = model.predict(encoded)\n",
    "\n",
    "print(\"Sentiment score:\", pred[0][0])\n",
    "print(\"Prediction:\", \"Positive üòä\" if pred[0][0] >= 0.5 else \"Negative üòû\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
